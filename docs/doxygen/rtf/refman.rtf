{\rtf1\ansi\ansicpg1252\uc1 \deff0\deflang1033\deflangfe1033
{\fonttbl {\f0\froman\fcharset0\fprq2{\*\panose 02020603050405020304}Times New Roman;}
{\f1\fswiss\fcharset0\fprq2{\*\panose 020b0604020202020204}Arial;}
{\f2\fmodern\fcharset0\fprq1{\*\panose 02070309020205020404}Courier New;}
{\f3\froman\fcharset2\fprq2{\*\panose 05050102010706020507}Symbol;}
}
{\colortbl;\red0\green0\blue0;\red0\green0\blue255;\red0\green255\blue255;\red0\green255\blue0;\red255\green0\blue255;\red255\green0\blue0;\red255\green255\blue0;\red255\green255\blue255;\red0\green0\blue128;\red0\green128\blue128;\red0\green128\blue0;\red128\green0\blue128;\red128\green0\blue0;\red128\green128\blue0;\red128\green128\blue128;\red192\green192\blue192;\red0\green128\blue0;\red96\green64\blue32;\rede0\green128\blue0;\red128\green0\blue0;\red128\green96\blue32;\red0\green32\blue128;\red0\green128\blue128;\red255\green0\blue255;\red0\green0\blue0;\red112\green0\blue112;\red255\green0\blue0;}
{\stylesheet
{\widctlpar\adjustright \fs20\cgrid \snext0 Normal;}
{\paperw11900\paperh16840\margl1800\margr1800\margt1440\margb1440\gutter0\ltrsect}
{\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid \sbasedon0 \snext0 heading 1;}
{\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid \sbasedon0 \snext0 heading 2;}
{\s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid \sbasedon0 \snext0 heading 3;}
{\s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid \sbasedon0 \snext0 heading 4;}{\*\cs10 \additive Default Paragraph Font;}
{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid \sbasedon0 \snext0 heading 5;}{\*\cs10 \additive Default Paragraph Font;}
{\s6\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs12\cgrid \sbasedon0 \snext0 heading 6;}{\*\cs10 \additive Default Paragraph Font;}
{\s15\qc\sb240\sa60\widctlpar\outlinelevel0\adjustright \b\f1\fs32\kerning28\cgrid \sbasedon0 \snext15 Title;}
{\s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid \sbasedon0 \snext16 Subtitle;}
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid \sbasedon0 \snext17 BodyText;}
{\s18\widctlpar\fs22\cgrid \sbasedon0 \snext18 DenseText;}
{\s28\widctlpar\tqc\tx4320\tqr\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext28 header;}
{\s29\widctlpar\tqc\tx4320\tqr\tx8640\qr\adjustright \fs20\cgrid \sbasedon0 \snext29 footer;}
{\s30\li360\sa60\sb120\keepn\widctlpar\adjustright \b\f1\fs20\cgrid \sbasedon0 \snext30 GroupHeader;}
{\s40\li0\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext41 Code Example 0;}
{\s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext42 Code Example 1;}
{\s42\li720\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext43 Code Example 2;}
{\s43\li1080\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext44 Code Example 3;}
{\s44\li1440\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext45 Code Example 4;}
{\s45\li1800\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext46 Code Example 5;}
{\s46\li2160\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext47 Code Example 6;}
{\s47\li2520\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext48 Code Example 7;}
{\s48\li2880\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext49 Code Example 8;}
{\s49\li3240\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext50 Code Example 9;}
{\s50\li3600\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext51 Code Example 10;}
{\s51\li3960\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext52 Code Example 11;}
{\s52\li4320\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext53 Code Example 12;}
{\s53\li4680\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext53 Code Example 13;}
{\s60\li0\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext61 List Continue 0;}
{\s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext62 List Continue 1;}
{\s62\li720\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext63 List Continue 2;}
{\s63\li1080\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext64 List Continue 3;}
{\s64\li1440\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext65 List Continue 4;}
{\s65\li1800\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext66 List Continue 5;}
{\s66\li2160\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext67 List Continue 6;}
{\s67\li2520\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext68 List Continue 7;}
{\s68\li2880\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext69 List Continue 8;}
{\s69\li3240\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext70 List Continue 9;}
{\s70\li3600\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext71 List Continue 10;}
{\s71\li3960\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext72 List Continue 11;}
{\s72\li4320\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext73 List Continue 12;}
{\s73\li4680\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext73 List Continue 13;}
{\s80\li0\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext81 DescContinue 0;}
{\s81\li360\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext82 DescContinue 1;}
{\s82\li720\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext83 DescContinue 2;}
{\s83\li1080\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext84 DescContinue 3;}
{\s84\li1440\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext85 DescContinue 4;}
{\s85\li1800\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext86 DescContinue 5;}
{\s86\li2160\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext87 DescContinue 6;}
{\s87\li2520\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext88 DescContinue 7;}
{\s88\li2880\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext89 DescContinue 8;}
{\s89\li3240\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext90 DescContinue 9;}
{\s90\li3600\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext91 DescContinue 10;}
{\s91\li3960\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext92 DescContinue 11;}
{\s92\li4320\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext93 DescContinue 12;}
{\s93\li4680\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext93 DescContinue 13;}
{\s100\li0\sa30\sb30\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext101 LatexTOC 0;}
{\s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext102 LatexTOC 1;}
{\s102\li720\sa24\sb24\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext103 LatexTOC 2;}
{\s103\li1080\sa21\sb21\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext104 LatexTOC 3;}
{\s104\li1440\sa18\sb18\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext105 LatexTOC 4;}
{\s105\li1800\sa15\sb15\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext106 LatexTOC 5;}
{\s106\li2160\sa12\sb12\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext107 LatexTOC 6;}
{\s107\li2520\sa9\sb9\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext108 LatexTOC 7;}
{\s108\li2880\sa6\sb6\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext109 LatexTOC 8;}
{\s109\li3240\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext110 LatexTOC 9;}
{\s110\li3600\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext111 LatexTOC 10;}
{\s111\li3960\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext112 LatexTOC 11;}
{\s112\li4320\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext113 LatexTOC 12;}
{\s113\li4680\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext113 LatexTOC 13;}
{\s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext121 \sautoupd List Bullet 0;}
{\s121\fi-360\li720\widctlpar\jclisttab\tx720{\*\pn \pnlvlbody\ilvl0\ls2\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext122 \sautoupd List Bullet 1;}
{\s122\fi-360\li1080\widctlpar\jclisttab\tx1080{\*\pn \pnlvlbody\ilvl0\ls3\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext123 \sautoupd List Bullet 2;}
{\s123\fi-360\li1440\widctlpar\jclisttab\tx1440{\*\pn \pnlvlbody\ilvl0\ls4\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext124 \sautoupd List Bullet 3;}
{\s124\fi-360\li1800\widctlpar\jclisttab\tx1800{\*\pn \pnlvlbody\ilvl0\ls5\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext125 \sautoupd List Bullet 4;}
{\s125\fi-360\li2160\widctlpar\jclisttab\tx2160{\*\pn \pnlvlbody\ilvl0\ls6\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext126 \sautoupd List Bullet 5;}
{\s126\fi-360\li2520\widctlpar\jclisttab\tx2520{\*\pn \pnlvlbody\ilvl0\ls7\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext127 \sautoupd List Bullet 6;}
{\s127\fi-360\li2880\widctlpar\jclisttab\tx2880{\*\pn \pnlvlbody\ilvl0\ls8\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext128 \sautoupd List Bullet 7;}
{\s128\fi-360\li3240\widctlpar\jclisttab\tx3240{\*\pn \pnlvlbody\ilvl0\ls9\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext129 \sautoupd List Bullet 8;}
{\s129\fi-360\li3600\widctlpar\jclisttab\tx3600{\*\pn \pnlvlbody\ilvl0\ls10\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext130 \sautoupd List Bullet 9;}
{\s130\fi-360\li3960\widctlpar\jclisttab\tx3960{\*\pn \pnlvlbody\ilvl0\ls11\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext131 \sautoupd List Bullet 10;}
{\s131\fi-360\li4320\widctlpar\jclisttab\tx4320{\*\pn \pnlvlbody\ilvl0\ls12\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext132 \sautoupd List Bullet 11;}
{\s132\fi-360\li4680\widctlpar\jclisttab\tx4680{\*\pn \pnlvlbody\ilvl0\ls13\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext133 \sautoupd List Bullet 12;}
{\s133\fi-360\li5040\widctlpar\jclisttab\tx5040{\*\pn \pnlvlbody\ilvl0\ls14\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext133 \sautoupd List Bullet 13;}
{\s140\fi-360\li360\widctlpar\fs20\cgrid \sbasedon0 \snext141 \sautoupd List Enum 0;}
{\s141\fi-360\li720\widctlpar\fs20\cgrid \sbasedon0 \snext142 \sautoupd List Enum 1;}
{\s142\fi-360\li1080\widctlpar\fs20\cgrid \sbasedon0 \snext143 \sautoupd List Enum 2;}
{\s143\fi-360\li1440\widctlpar\fs20\cgrid \sbasedon0 \snext144 \sautoupd List Enum 3;}
{\s144\fi-360\li1800\widctlpar\fs20\cgrid \sbasedon0 \snext145 \sautoupd List Enum 4;}
{\s145\fi-360\li2160\widctlpar\fs20\cgrid \sbasedon0 \snext146 \sautoupd List Enum 5;}
{\s146\fi-360\li2520\widctlpar\fs20\cgrid \sbasedon0 \snext147 \sautoupd List Enum 6;}
{\s147\fi-360\li2880\widctlpar\fs20\cgrid \sbasedon0 \snext148 \sautoupd List Enum 7;}
{\s148\fi-360\li3240\widctlpar\fs20\cgrid \sbasedon0 \snext149 \sautoupd List Enum 8;}
{\s149\fi-360\li3600\widctlpar\fs20\cgrid \sbasedon0 \snext150 \sautoupd List Enum 9;}
{\s150\fi-360\li3960\widctlpar\fs20\cgrid \sbasedon0 \snext151 \sautoupd List Enum 10;}
{\s151\fi-360\li4320\widctlpar\fs20\cgrid \sbasedon0 \snext152 \sautoupd List Enum 11;}
{\s152\fi-360\li4680\widctlpar\fs20\cgrid \sbasedon0 \snext153 \sautoupd List Enum 12;}
{\s153\fi-360\li5040\widctlpar\fs20\cgrid \sbasedon0 \snext153 \sautoupd List Enum 13;}
}
{\*\listtable
{\list\listtemplateid1
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li360 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9702 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li720 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9642 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li1080 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li1440 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9702 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li1800 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9642 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li2160 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8662 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li2520 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9702 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li2880 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9642 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li3600 }
\listid1}
{\list\listtemplateid2
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9744 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li360 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9744 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li720 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9744 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li1080 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9744 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li1440 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9744 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li1800 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9744 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li2160 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9744 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li2520 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9744 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li2880 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9744 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li3600 }
\listid2}
{\list\listtemplateid3
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9746 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li360 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9746 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li720 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9746 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li1080 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9746 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li1440 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9746 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li1800 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9746 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li2160 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9746 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li2520 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9746 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li2880 }
{ \listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u9746 ?;}{\levelnumbers;}\f8\dbch\af3\fi-360\li3600 }
\listid3}
}
{\listoverridetable
{\listoverride\listid1\listoverridecount0\ls1}
{\listoverride\listid2\listoverridecount0\ls2}
{\listoverride\listid3\listoverridecount0\ls3}
}
{\info 
{\title {\comment CNeural  {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
0.0.1 \par
}}CNeural}
{\comment Generated by doxygen 1.12.0.}
}\pard\plain 
\sectd\pgnlcrm
{\footer \s29\widctlpar\tqc\tx4320\tqr\tx8640\qr\adjustright \fs20\cgrid {\chpgn}}
\pard\plain \s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid 
\vertalc\qc\par\par\par\par\par\par\par
\pard\plain \s15\qc\sb240\sa60\widctlpar\outlinelevel0\adjustright \b\f1\fs32\kerning28\cgrid 
{\field\fldedit {\*\fldinst TITLE \\*MERGEFORMAT}{\fldrslt CNeural}}\par
\pard\plain \s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid 
\par
\par\par\par\par\par\par\par\par\par\par\par\par
\pard\plain \s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid 
{\field\fldedit {\*\fldinst AUTHOR \\*MERGEFORMAT}{\fldrslt AUTHOR}}\par
Version 0.0.1\par\page\page\vertalt
\pard\plain 
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid Table of Contents\par
\pard\plain \par
{\field\fldedit {\*\fldinst TOC \\f \\*MERGEFORMAT}{\fldrslt Table of contents}}\par
\pard\plain 
\sect \sbkpage \pgndec \pgnrestart
\sect \sectd \sbknone
{\footer \s29\widctlpar\tqc\tx4320\tqr\tx8640\qr\adjustright \fs20\cgrid {\chpgn}}

\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
Data Structure Index\par \pard\plain 
{\tc \v Data Structure Index}
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
Data Structures\par \pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid Here are the data structures with brief descriptions:}
{
\par
\pard\plain \s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid 
{\b {\b Layer} ({\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{\b Layer} type })} \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAABA \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
{\b {\b NeuralNetwork} ({\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Neural Network type })} \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAABG \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
{\b {\b Node} ({\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{\b Node} type })} \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAABS \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
\par}
\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
File Index\par \pard\plain 
{\tc \v File Index}
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
File List\par \pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid Here is a list of all documented files with brief descriptions:}
{
\par
\pard\plain \s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid 
{\b {\b CNeural.c} ({\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Source file for CNeural, containing function definitions })} \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAB \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
{\b {\b CNeural.h} ({\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Header file for CNeural, containing data structures and function declarations })} \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAK \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
{\b {\b CNeural_backpropagation.c} ({\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Source file for CNeural backpropagation, containing function definitions })} \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAW \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
\par}
\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
Data Structure Documentation{\tc \v Data Structure Documentation}
\par \pard\plain 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
Layer Struct Reference\par \pard\plain 
{\tc\tcl2 \v Layer}
{\xe \v Layer}
{\bkmkstart AAAAAAAABA}
{\bkmkend AAAAAAAABA}
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{\b Layer} type. }}\par
{
{\f2 #include <CNeural.h>}}\par
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Data Fields\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
int {\b nNodes}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\b Node} * {\b nodes}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
string {\b layerAF}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
float * {\b weightedSum}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
float * {\b nodesResults}\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Detailed Description\par
\pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{\b Layer} type. \par
}

{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{\b Layer} type in a neural network. \par
}}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Field Documentation\par
\pard\plain 
{\xe \v layerAF\:Layer}
{\xe \v Layer\:layerAF}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
string layerAF}}
\par
{\bkmkstart AAAAAAAABB}
{\bkmkend AAAAAAAABB}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
corresponding activations apply to the whole layer, adjust accordingly by changing individual node activations \par
}}
{\xe \v nNodes\:Layer}
{\xe \v Layer\:nNodes}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
int nNodes}}
\par
{\bkmkstart AAAAAAAABC}
{\bkmkend AAAAAAAABC}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
number of nodes \par
}}
{\xe \v nodes\:Layer}
{\xe \v Layer\:nodes}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
{\b Node}* nodes}}
\par
{\bkmkstart AAAAAAAABD}
{\bkmkend AAAAAAAABD}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
array of nodes \par
}}
{\xe \v nodesResults\:Layer}
{\xe \v Layer\:nodesResults}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
float* nodesResults}}
\par
{\bkmkstart AAAAAAAABE}
{\bkmkend AAAAAAAABE}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{\b Layer} output, weighted sums array that have passed through the activation function as input to the next layer. \par
}}
{\xe \v weightedSum\:Layer}
{\xe \v Layer\:weightedSum}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
float* weightedSum}}
\par
{\bkmkstart AAAAAAAABF}
{\bkmkend AAAAAAAABF}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
weighted sums array of linear combinations before passing through the activation function \par
}}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
The documentation for this struct was generated from the following file:{\par
\pard\plain \s121\fi-360\li720\widctlpar\jclisttab\tx720{\*\pn \pnlvlbody\ilvl0\ls2\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\b CNeural.h}}\par \pard\plain 

\pard\plain \sect\sbkpage
\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
NeuralNetwork Struct Reference\par \pard\plain 
{\tc\tcl2 \v NeuralNetwork}
{\xe \v NeuralNetwork}
{\bkmkstart AAAAAAAABG}
{\bkmkend AAAAAAAABG}
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Neural Network type. }}\par
{
{\f2 #include <CNeural.h>}}\par
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Data Fields\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
int {\b inShape}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
int {\b nLayers}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
int {\b outShape}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
int {\b nLabels}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
string {\b lf}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
float {\b loss}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
string {\b opt}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
float {\b lr}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
int {\b epochs}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
float * {\b labels}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\b Layer} * {\b layers}\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Detailed Description\par
\pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Neural Network type. \par
}}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Field Documentation\par
\pard\plain 
{\xe \v epochs\:NeuralNetwork}
{\xe \v NeuralNetwork\:epochs}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
int epochs}}
\par
{\bkmkstart AAAAAAAABH}
{\bkmkend AAAAAAAABH}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
number of epochs (forward passes through the whole dataset) \par
}}
{\xe \v inShape\:NeuralNetwork}
{\xe \v NeuralNetwork\:inShape}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
int inShape}}
\par
{\bkmkstart AAAAAAAABI}
{\bkmkend AAAAAAAABI}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
input shape, the input number of nodes \par
}}
{\xe \v labels\:NeuralNetwork}
{\xe \v NeuralNetwork\:labels}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
float* labels}}
\par
{\bkmkstart AAAAAAAABJ}
{\bkmkend AAAAAAAABJ}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
array of labels for training \par
}}
{\xe \v layers\:NeuralNetwork}
{\xe \v NeuralNetwork\:layers}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
{\b Layer}* layers}}
\par
{\bkmkstart AAAAAAAABK}
{\bkmkend AAAAAAAABK}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
array of layers \par
}}
{\xe \v lf\:NeuralNetwork}
{\xe \v NeuralNetwork\:lf}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
string lf}}
\par
{\bkmkstart AAAAAAAABL}
{\bkmkend AAAAAAAABL}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
loss function \par
}}
{\xe \v loss\:NeuralNetwork}
{\xe \v NeuralNetwork\:loss}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
float loss}}
\par
{\bkmkstart AAAAAAAABM}
{\bkmkend AAAAAAAABM}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
the error rate of the network (after each epoch) \par
}}
{\xe \v lr\:NeuralNetwork}
{\xe \v NeuralNetwork\:lr}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
float lr}}
\par
{\bkmkstart AAAAAAAABN}
{\bkmkend AAAAAAAABN}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
learning rate \par
}}
{\xe \v nLabels\:NeuralNetwork}
{\xe \v NeuralNetwork\:nLabels}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
int nLabels}}
\par
{\bkmkstart AAAAAAAABO}
{\bkmkend AAAAAAAABO}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
number of labels \par
}}
{\xe \v nLayers\:NeuralNetwork}
{\xe \v NeuralNetwork\:nLayers}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
int nLayers}}
\par
{\bkmkstart AAAAAAAABP}
{\bkmkend AAAAAAAABP}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
number of layers \par
}}
{\xe \v opt\:NeuralNetwork}
{\xe \v NeuralNetwork\:opt}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
string opt}}
\par
{\bkmkstart AAAAAAAABQ}
{\bkmkend AAAAAAAABQ}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
optimizer \par
}}
{\xe \v outShape\:NeuralNetwork}
{\xe \v NeuralNetwork\:outShape}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
int outShape}}
\par
{\bkmkstart AAAAAAAABR}
{\bkmkend AAAAAAAABR}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
output shape, the final output number of nodes \par
}}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
The documentation for this struct was generated from the following file:{\par
\pard\plain \s121\fi-360\li720\widctlpar\jclisttab\tx720{\*\pn \pnlvlbody\ilvl0\ls2\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\b CNeural.h}}\par \pard\plain 

\pard\plain \sect\sbkpage
\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
Node Struct Reference\par \pard\plain 
{\tc\tcl2 \v Node}
{\xe \v Node}
{\bkmkstart AAAAAAAABS}
{\bkmkend AAAAAAAABS}
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{\b Node} type. }}\par
{
{\f2 #include <CNeural.h>}}\par
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Data Fields\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
float * {\b weights}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
float {\b bias}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
float * {\b weightDerivatives}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
float {\b biasDerivative}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
string {\b AF}\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Detailed Description\par
\pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{\b Node} type. \par
}

{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{\b Node} type in each layer. \par
}}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Field Documentation\par
\pard\plain 
{\xe \v AF\:Node}
{\xe \v Node\:AF}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
string AF}}
\par
{\bkmkstart AAAAAAAABT}
{\bkmkend AAAAAAAABT}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
node activation function \par
}}
{\xe \v bias\:Node}
{\xe \v Node\:bias}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
float bias}}
\par
{\bkmkstart AAAAAAAABU}
{\bkmkend AAAAAAAABU}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
bias value \par
}}
{\xe \v biasDerivative\:Node}
{\xe \v Node\:biasDerivative}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
float biasDerivative}}
\par
{\bkmkstart AAAAAAAABV}
{\bkmkend AAAAAAAABV}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
corresponding nudge to the bias in gradient descent \par
}}
{\xe \v weightDerivatives\:Node}
{\xe \v Node\:weightDerivatives}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
float* weightDerivatives}}
\par
{\bkmkstart AAAAAAAABW}
{\bkmkend AAAAAAAABW}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
corresponding nudges to weights in gradient descent \par
}}
{\xe \v weights\:Node}
{\xe \v Node\:weights}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
float* weights}}
\par
{\bkmkstart AAAAAAAABX}
{\bkmkend AAAAAAAABX}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
array of weights \par
}}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
The documentation for this struct was generated from the following file:{\par
\pard\plain \s121\fi-360\li720\widctlpar\jclisttab\tx720{\*\pn \pnlvlbody\ilvl0\ls2\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\b CNeural.h}}
\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
File Documentation{\tc \v File Documentation}
\par \pard\plain 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
CNeural.c File Reference\par \pard\plain 
{\tc\tcl2 \v CNeural.c}
{\xe \v CNeural.c}
{\bkmkstart AAAAAAAAAB}
{\bkmkend AAAAAAAAAB}
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Source file for CNeural, containing function definitions. }}\par
{
\pard\plain \s18\widctlpar\fs22\cgrid {\f2 #include <stdio.h>}\par
{\f2 #include <stdlib.h>}\par
{\f2 #include <math.h>}\par
{\f2 #include <string.h>}\par
{\f2 #include <time.h>}\par
{\f2 #include "CNeural.h"}\par
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Macros\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 

#define {\b AFStringSize}\~ 10{\bkmkstart AAAAAAAAAC}
{\bkmkend AAAAAAAAAC}
\par
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Functions\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
int {\b CNeural_init} ({\b NeuralNetwork} *nn, int inputShape, int outputShape, int numLayers, int layerNumNodes[], string layersAF[], string initMethod)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
void {\b CNeural_clear_nodeResults} ({\b NeuralNetwork} *nn, int layerNum)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
int {\b CNeural_wb_init} ({\b NeuralNetwork} *nn, int layerNum, string option)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
void {\b CNeural_train} ({\b NeuralNetwork} *nn, int numLabels, float inputs[numLabels][nn->inShape], float labels[numLabels][nn->outShape], string lossFunction, string optimizer, float learningRate, int epochs)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
float {\b CNeural_activation} (float input, string af)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
float {\b CNeural_loss} (float predicted[], float actual[], int outputShape, string lfn)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
void {\b CNeural_free} ({\b NeuralNetwork} *nn)\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Detailed Description\par
\pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Source file for CNeural, containing function definitions. \par
}{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Author\par}\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
Dai Duong Le \par
}}{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Version\par}\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
: 0.0.1 \par
}}}}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Function Documentation\par
\pard\plain 
{\xe \v CNeural_activation\:CNeural.c}
{\xe \v CNeural.c\:CNeural_activation}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
float CNeural_activation (float input, string af)}}
\par
{\bkmkstart AAAAAAAAAD}
{\bkmkend AAAAAAAAAD}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Activation function. Helper function to CNeural_train.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i input} \cell }{value to pass through the specified activation \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i af} \cell }{a string corresponding to an activation function, values: "none", "sigmoid", "tanh", "relu", default: "relu" \cell }
{\row }
}
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Returns\par}\pard\plain \s82\li720\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
processed value by the activation \par
}}}{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 219                                                  \{\par
220     {\cf19 if} (strcmp(af, {\cf22 "none"}) == 0) {\cf19 return} input;\par
221 \par
222     {\cf19 if} (strcmp(af, {\cf22 "sigmoid"}) == 0) \{\par
223         {\cf19 return} 1 / (1 + expf(-input));\par
224     \}\par
225     {\cf19 if} (strcmp(af, {\cf22 "tanh"}) == 0) \{\par
226         {\cf19 return} tanhf(input);\par
227     \}\par
228     {\cf19 if} (strcmp(af, {\cf22 "relu"}) == 0) \{\par
229         {\cf19 return} fmaxf(0, input);\par
230     \}\par
231     printf({\cf22 "Warning: Unknown activation function. Training results might not be optimal!\\n"});\par
232     printf({\cf22 "Defaulting to ReLu\\n"});\par
233     {\cf19 return} fmaxf(0, input);\par
234 \}\par
}
}
{\xe \v CNeural_clear_nodeResults\:CNeural.c}
{\xe \v CNeural.c\:CNeural_clear_nodeResults}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
void CNeural_clear_nodeResults ({\b NeuralNetwork} * nn, int layerNum)}}
\par
{\bkmkstart AAAAAAAAAE}
{\bkmkend AAAAAAAAAE}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Clears nodeResults array.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i nn} \cell }{neural network type \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i layerNum} \cell }{layer number \cell }
{\row }
}
}{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 80                                                                 \{\par
81     {\cf19 for} ({\cf18 int} i = 0; i < nn->layers[layerNum].nNodes; i++) \{\par
82         nn->layers[layerNum].nodesResults[i] = 0;\par
83     \}\par
84 \}\par
}
}
{\xe \v CNeural_free\:CNeural.c}
{\xe \v CNeural.c\:CNeural_free}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
void CNeural_free ({\b NeuralNetwork} * nn)}}
\par
{\bkmkstart AAAAAAAAAF}
{\bkmkend AAAAAAAAAF}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Frees all allocated memory of a neural network.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i nn} \cell }{neural network type \cell }
{\row }
}
}{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 275                                      \{\par
276     {\cf20 // free(nn->)}\par
277     free(nn);\par
278 \}\par
}
}
{\xe \v CNeural_init\:CNeural.c}
{\xe \v CNeural.c\:CNeural_init}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
int CNeural_init ({\b NeuralNetwork} * nn, int inputShape, int outputShape, int numLayers, int layerNumNodes[], string layersAF[], string initMethod)}}
\par
{\bkmkstart AAAAAAAAAG}
{\bkmkend AAAAAAAAAG}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Initializes a neural network.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i nn} \cell }{neural network type \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i inputShape} \cell }{input number of nodes \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i outputShape} \cell }{output number of nodes \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i numLayers} \cell }{number of layers \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i layerNumNodes} \cell }{array with each layer's number of nodes \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i layersAF} \cell }{layer activation function \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i initMethod} \cell }{initialization method \cell }
{\row }
}
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Returns\par}\pard\plain \s82\li720\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
returns 0 for success \par
}}}{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 40                                                                                                                                                \{\par
41     nn->inShape = inputShape;\par
42     nn->outShape = outputShape;\par
43     nn->nLayers = numLayers;\par
44 \par
45     nn->layers = malloc({\cf17 sizeof}(Layer) * ({\cf18 unsigned} {\cf18 int}) nn->nLayers); {\cf20 // not freed}\par
46     {\cf19 if} (nn->layers == NULL) \{\par
47         printf({\cf22 "Error: Failed to allocate memory!"});\par
48         {\cf19 return} 1;\par
49     \}\par
50 \par
51     {\cf19 for} ({\cf18 int} i = 0; i < nn->nLayers; i++) \{ {\cf20 // initialize each LAYER with nodes and activation functions}\par
52         nn->layers[i].nNodes = layerNumNodes[i];\par
53         nn->layers[i].layerAF = layersAF[i];\par
54 \par
55 \par
56         nn->layers[i].nodes = malloc({\cf17 sizeof}(Node) * ({\cf18 unsigned} {\cf18 int}) nn->layers[i].nNodes); {\cf20 // not freed}\par
57         nn->layers[i].weightedSum = malloc({\cf17 sizeof}({\cf18 float}) * ({\cf18 unsigned} {\cf18 int}) nn->layers[i].nNodes); {\cf20 // not freed}\par
58         nn->layers[i].nodesResults = malloc({\cf17 sizeof}({\cf18 float}) * ({\cf18 unsigned} {\cf18 int}) nn->layers[i].nNodes); {\cf20 // not freed}\par
59         CNeural_clear_nodeResults(nn, i); {\cf20 // init with 0 to clear garbage values}\par
60 \par
61         {\cf19 if} (nn->layers[i].nodes == NULL || nn->layers[i].weightedSum == NULL || nn->layers[i].nodesResults == NULL) \{\par
62             printf({\cf22 "Error: Failed to allocate memory!"});\par
63             {\cf19 return} 1;\par
64         \}\par
65 \par
66         {\cf19 if} (CNeural_wb_init(nn, i, initMethod) != 0) \{\par
67             {\cf19 return} 1;\par
68         \}\par
69     \}\par
70 \par
71     {\cf19 return} 0;\par
72 \}\par
}
}
{\xe \v CNeural_loss\:CNeural.c}
{\xe \v CNeural.c\:CNeural_loss}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
float CNeural_loss (float predicted[], float actual[], int outputShape, string lfn)}}
\par
{\bkmkstart AAAAAAAAAH}
{\bkmkend AAAAAAAAAH}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Loss function. Helper function to CNeural_train.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i predicted} \cell }{array of predicted values (nodeResult values of the last layer) for 1 training example \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i actual} \cell }{array of label values to compare to for 1 training example \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i outputShape} \cell }{number of output nodes \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i lfn} \cell }{a string corresponding to a loss function, values: "mse", "mae", default: "mse" \cell }
{\row }
}
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Returns\par}\pard\plain \s82\li720\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
loss value \par
}}}{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 245                                                                                    \{\par
246     {\cf19 if} (strcmp(lfn, {\cf22 "mse"}) == 0) \{ {\cf20 // Mean Squared Error}\par
247         {\cf18 float} sum = 0;\par
248         {\cf19 for} ({\cf18 int} i = 0; i < outputShape; i++) \{\par
249             sum += powf(predicted[i] - actual[i], 2);\par
250         \}\par
251         {\cf19 return} sum;\par
252     \}\par
253     {\cf19 if} (strcmp(lfn, {\cf22 "mae"}) == 0) \{ {\cf20 // Mean Average Error}\par
254         {\cf18 float} sum = 0;\par
255         {\cf19 for} ({\cf18 int} i = 0; i < outputShape; i++) \{\par
256             sum += fabsf(predicted[i] - actual[i]);\par
257         \}\par
258         {\cf19 return} sum;\par
259     \}\par
260 \par
261     printf({\cf22 "Warning: Unknown loss function. Training results might not be optimal!\\n"});\par
262     printf({\cf22 "Defaulting to MSE\\n"});\par
263     {\cf18 float} sum = 0;\par
264     {\cf19 for} ({\cf18 int} i = 0; i < outputShape; i++) \{\par
265         sum += powf(predicted[i] - actual[i], 2);\par
266     \}\par
267     {\cf19 return} sum;\par
268 \}\par
}
}
{\xe \v CNeural_train\:CNeural.c}
{\xe \v CNeural.c\:CNeural_train}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
void CNeural_train ({\b NeuralNetwork} * nn, int numLabels, float inputs[numLabels][nn->inShape], float labels[numLabels][nn->outShape], string lossFunction, string optimizer, float learningRate, int epochs)}}
\par
{\bkmkstart AAAAAAAAAI}
{\bkmkend AAAAAAAAAI}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Trains a neural network using the specified parameters.\par
Weighted sums get forward propagated (forward pass) by calculating linear combinations applying an activation function for each node in each layer. After all the training examples go through 1 epoch, the loss and gradient are calculated based on the optimizer. Neural network parameters are adjusted with the learning rate accordingly.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i nn} \cell }{neural network type \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i numLabels} \cell }{number of labels (training examples) \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i inputs} \cell }{array of inputs (features) \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i labels} \cell }{array of labels \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i lossFunction} \cell }{a string corresponding to a loss function \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i optimizer} \cell }{a string corresponding to an optimizer \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i learningRate} \cell }{learning rate to be applied in gradient descent \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i epochs} \cell }{number of epochs (forward passes through the whole dataset) \cell }
{\row }
}
}{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 148                                                                                                                                                                                                          \{\par
149     nn->nLabels = numLabels;\par
150     nn->lf = lossFunction;\par
151     nn->opt = optimizer;\par
152     nn->lr = learningRate;\par
153     nn->epochs = epochs;\par
154 \par
155     {\cf20 // TODO loss and expand activation functions}\par
156     {\cf19 for} ({\cf18 int} epoch = 1; epoch <= nn->epochs; epoch++) \{\par
157         printf({\cf22 "Epoch %d/%d\\n"}, epoch, nn->epochs);\par
158         {\cf19 for} ({\cf18 int} label = 0; label < numLabels; label++) \{\par
159             {\cf20 // printf("Label: %d\\n", label + 1);}\par
160 \par
161             {\cf19 for} ({\cf18 int} layerNum = 0; layerNum < nn->nLayers; layerNum++) \{\par
162                 {\cf20 // printf("Layer %d\\n", layerNum + 1);}\par
163 \par
164                 {\cf19 for} ({\cf18 int} nodeNum = 0; nodeNum < nn->layers[layerNum].nNodes; nodeNum++) \{\par
165                     {\cf20 // printf("\\tNode %d\\n", nodeNum + 1);}\par
166                     {\cf19 if} (layerNum == 0) \{ {\cf20 // 1st layer # of weights should = # of inputs}\par
167                         {\cf19 for} ({\cf18 int} weightNum = 0; weightNum < nn->inShape; weightNum++) \{\par
168                             {\cf20 // printf("\\t\\tWeight %d: %f ", weightNum + 1, nn->layers[0].nodes[nodeNum].weights[weightNum]);}\par
169                             nn->layers[layerNum].nodesResults[nodeNum] +=\par
170                                 nn->layers[layerNum].nodes[nodeNum].weights[weightNum] * inputs[label][weightNum]; {\cf20 // adds for each linear combination (weighted sum)}\par
171 \par
172                             {\cf20 // printf("Noderes value: %f\\n", nn->layers[0].nodesResults[nodeNum]);}\par
173                         \}\par
174                     \} {\cf19 else} \{  {\cf20 // # of weights should = previous layer # of nodes}\par
175                         {\cf19 for} ({\cf18 int} weightNum = 0; weightNum < nn->layers[layerNum - 1].nNodes; weightNum++) \{\par
176                             {\cf20 // printf("\\t\\tWeight %d: %f \\t", weightNum + 1, nn->layers[layerNum].nodes[nodeNum].weights[weightNum]);}\par
177                             nn->layers[layerNum].nodesResults[nodeNum] +=\par
178                                 nn->layers[layerNum].nodes[nodeNum].weights[weightNum] * nn->layers[layerNum - 1].nodesResults[weightNum]; {\cf20 // adds for each linear combination (weighted sum)}\par
179                             {\cf20 // printf("Noderes value: %f\\n", nn->layers[layerNum].nodesResults[nodeNum]);}\par
180                         \}\par
181                     \}\par
182                     nn->layers[layerNum].nodesResults[nodeNum] += nn->layers[layerNum].nodes[nodeNum].bias;\par
183                     {\cf20 // printf("\\n");}\par
184                     {\cf20 // printf("\\t\\tAfter bias: %f\\n", nn->layers[layerNum].nodesResults[nodeNum]);}\par
185 \par
186                     {\cf20 // printf("\\t\\tAfter activation: %f\\n", CNeural_activation(nn->layers[layerNum].nodesResults[nodeNum], nn->layers[layerNum].nodes[nodeNum].AF));}\par
187                     nn->layers[layerNum].weightedSum[nodeNum] = nn->layers[layerNum].nodesResults[nodeNum];\par
188                     nn->layers[layerNum].nodesResults[nodeNum] =\par
189                         CNeural_activation(nn->layers[layerNum].nodesResults[nodeNum], nn->layers[layerNum].nodes[nodeNum].AF);\par
190                     {\cf20 // printf("\\n");}\par
191                 \}\par
192 \par
193                 {\cf20 // printf("\\n");}\par
194             \}\par
195 \par
196             nn->loss += CNeural_loss(nn->layers[nn->nLayers - 1].nodesResults, labels[label], nn->outShape, nn->lf);\par
197 \par
198             {\cf20 // CNeural_derivatives()}\par
199 \par
200             {\cf19 for} ({\cf18 int} layerNum = 0; layerNum < nn->nLayers; layerNum++) \{ {\cf20 // clear after each label}\par
201                 CNeural_clear_nodeResults(nn, layerNum);\par
202             \}\par
203         \}\par
204         nn->loss = nn->loss / (float) nn->nLabels;\par
205         printf({\cf22 "Loss: %f\\n"}, nn->loss);\par
206         printf({\cf22 "\\n"});\par
207 \par
208     \}\par
209 \par
210 \}\par
}
}
{\xe \v CNeural_wb_init\:CNeural.c}
{\xe \v CNeural.c\:CNeural_wb_init}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
int CNeural_wb_init ({\b NeuralNetwork} * nn, int layerNum, string option)}}
\par
{\bkmkstart AAAAAAAAAJ}
{\bkmkend AAAAAAAAAJ}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Initializes the weights and biases. Helper function to CNeural_init.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i nn} \cell }{neural network type \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i layerNum} \cell }{layer number \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i option} \cell }{a string corresponding to an initialization method, values: "zero", "random" \cell }
{\row }
}
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Returns\par}\pard\plain \s82\li720\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
returns 0 for sucess \par
}}}{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 94                                                                     \{\par
95     {\cf20 //TODO (optional) calculate mean, variance, standard deviation for measuring appropriateness}\par
96     srand(({\cf18 unsigned} {\cf18 int}) time(NULL)); {\cf20 // init random generator}\par
97 \par
98     {\cf19 if} (strcmp(option, {\cf22 "zero"}) == 0) \{\par
99         {\cf20 // probably not a good init option}\par
100     \} {\cf19 else} {\cf19 if} (strcmp(option, {\cf22 "random"}) == 0) \{\par
101         {\cf19 for} ({\cf18 int} i = 0; i < nn->layers[layerNum].nNodes; i++) \{ {\cf20 // for each NODE in layer init weights}\par
102             {\cf19 if} (layerNum == 0) \{ {\cf20 // first layer # of weights should = # of inputs}\par
103                 nn->layers[layerNum].nodes[i].weights = malloc({\cf17 sizeof}({\cf18 float}) * ({\cf18 unsigned} {\cf18 int}) nn->inShape); {\cf20 // not freed}\par
104                 nn->layers[layerNum].nodes[i].weightDerivatives = malloc({\cf17 sizeof}({\cf18 float}) * ({\cf18 unsigned} {\cf18 int}) nn->inShape); {\cf20 // not freed}\par
105                 {\cf19 if} (nn->layers[layerNum].nodes[i].weights == NULL || nn->layers[layerNum].nodes[i].weightDerivatives == NULL) \{ printf({\cf22 "Error: Failed to allocate memory!"}); {\cf19 return} 1; \}\par
106                 {\cf19 for} ({\cf18 int} j = 0; j < nn->inShape; j++) \{ {\cf20 // for each WEIGHT in node}\par
107                     nn->layers[layerNum].nodes[i].weights[j] = (float) (rand() / (({\cf18 double}) RAND_MAX + 1.0));\par
108                     nn->layers[layerNum].nodes[i].weightDerivatives[j] = 0;\par
109                 \}\par
110             \} {\cf19 else} \{  {\cf20 // # of weights should = previous layer # of nodes}\par
111                 nn->layers[layerNum].nodes[i].weights = malloc({\cf17 sizeof}({\cf18 float}) * ({\cf18 unsigned} {\cf18 int}) nn->layers[layerNum - 1].nNodes); {\cf20 // not freed}\par
112                 nn->layers[layerNum].nodes[i].weightDerivatives = malloc({\cf17 sizeof}({\cf18 float}) * ({\cf18 unsigned} {\cf18 int}) nn->inShape); {\cf20 // not freed}\par
113                 {\cf19 if} (nn->layers[layerNum].nodes[i].weights == NULL || nn->layers[layerNum].nodes[i].weightDerivatives == NULL) \{ printf({\cf22 "Error: Failed to allocate memory!"}); {\cf19 return} 1; \}\par
114                 {\cf19 for} ({\cf18 int} j = 0; j < nn->layers[layerNum - 1].nNodes; j++) \{ {\cf20 // for each WEIGHT in node}\par
115                     nn->layers[layerNum].nodes[i].weights[j] = (float) (rand() / (({\cf18 double}) RAND_MAX + 1.0));\par
116                     nn->layers[layerNum].nodes[i].weightDerivatives[j] = 0;\par
117                 \}\par
118             \}\par
119             nn->layers[layerNum].nodes[i].bias = 0; {\cf20 // bias can be 0}\par
120             nn->layers[layerNum].nodes[i].biasDerivative = 0;\par
121             nn->layers[layerNum].nodes[i].AF = nn->layers[layerNum].layerAF; {\cf20 // applies to the whole layer}\par
122         \}\par
123     \} {\cf19 else} \{\par
124         printf({\cf22 "Error: Unknown initialization method."});\par
125         {\cf19 return} 1;\par
126     \}\par
127 \par
128     {\cf19 return} 0;\par
129 \}\par
}
}
\par \pard\plain 

\pard\plain \sect\sbkpage
\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
CNeural.h File Reference\par \pard\plain 
{\tc\tcl2 \v CNeural.h}
{\xe \v CNeural.h}
{\bkmkstart AAAAAAAAAK}
{\bkmkend AAAAAAAAAK}
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Header file for CNeural, containing data structures and function declarations. }}\par
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Data Structures\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
struct {\b Node}{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{\b Node} type. }}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
struct {\b Layer}{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{\b Layer} type. }}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
struct {\b NeuralNetwork}{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Neural Network type. }}\par}
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Typedefs\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 

typedef char * {\b string}{\bkmkstart AAAAAAAAAL}
{\bkmkend AAAAAAAAAL}
\par
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Functions\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
int {\b CNeural_init} ({\b NeuralNetwork} *nn, int inputShape, int outputShape, int numLayers, int layerNumNodes[], string layersAF[], string initMethod)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
void {\b CNeural_clear_nodeResults} ({\b NeuralNetwork} *nn, int layerNum)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
int {\b CNeural_wb_init} ({\b NeuralNetwork} *nn, int layerNum, string option)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
void {\b CNeural_train} ({\b NeuralNetwork} *nn, int numLabels, float inputs[numLabels][nn->inShape], float labels[numLabels][nn->outShape], string lossFunction, string optimizer, float learningRate, int epochs)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
float {\b CNeural_activation} (float input, string af)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
float {\b CNeural_loss} (float predicted[], float actual[], int outputShape, string lfn)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
void {\b CNeural_free} ({\b NeuralNetwork} *nn)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
void {\b CNeural_derivatives} ({\b NeuralNetwork} *nn, float inputs[], float labels[], string lossFunction)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
float {\b CNeural_af_derivative} (float input, string af)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
float {\b CNeural_loss_derivative} (float predicted, float actual, string lfn)\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Detailed Description\par
\pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Header file for CNeural, containing data structures and function declarations. \par
}{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Author\par}\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
Dai Duong Le \par
}}{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Version\par}\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
: 0.0.1 \par
}}}}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Function Documentation\par
\pard\plain 
{\xe \v CNeural_activation\:CNeural.h}
{\xe \v CNeural.h\:CNeural_activation}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
float CNeural_activation (float input, string af)}}
\par
{\bkmkstart AAAAAAAAAM}
{\bkmkend AAAAAAAAAM}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Activation function. Helper function to CNeural_train.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i input} \cell }{value to pass through the specified activation \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i af} \cell }{a string corresponding to an activation function, values: "none", "sigmoid", "tanh", "relu", default: "relu" \cell }
{\row }
}
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Returns\par}\pard\plain \s82\li720\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
processed value by the activation \par
}}}{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 219                                                  \{\par
220     {\cf19 if} (strcmp(af, {\cf22 "none"}) == 0) {\cf19 return} input;\par
221 \par
222     {\cf19 if} (strcmp(af, {\cf22 "sigmoid"}) == 0) \{\par
223         {\cf19 return} 1 / (1 + expf(-input));\par
224     \}\par
225     {\cf19 if} (strcmp(af, {\cf22 "tanh"}) == 0) \{\par
226         {\cf19 return} tanhf(input);\par
227     \}\par
228     {\cf19 if} (strcmp(af, {\cf22 "relu"}) == 0) \{\par
229         {\cf19 return} fmaxf(0, input);\par
230     \}\par
231     printf({\cf22 "Warning: Unknown activation function. Training results might not be optimal!\\n"});\par
232     printf({\cf22 "Defaulting to ReLu\\n"});\par
233     {\cf19 return} fmaxf(0, input);\par
234 \}\par
}
}
{\xe \v CNeural_af_derivative\:CNeural.h}
{\xe \v CNeural.h\:CNeural_af_derivative}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
float CNeural_af_derivative (float input, string af)}}
\par
{\bkmkstart AAAAAAAAAN}
{\bkmkend AAAAAAAAAN}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Calculates the partial derivative of the activation function with respect to a weighted sum. Helper function to CNeural_derivatives.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i input} \cell }{value of weighted sum \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i af} \cell }{a string corresponding to an activation function, values: "none", "sigmoid", "tanh", "relu", default: "relu" \cell }
{\row }
}
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Returns\par}\pard\plain \s82\li720\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
rate of change of the activation function with respect to a weighted sum \par
}}}{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 48                                                     \{\par
49     {\cf19 if} (strcmp(af, {\cf22 "none"}) == 0) {\cf19 return} 1;\par
50     {\cf19 if} (strcmp(af, {\cf22 "sigmoid"}) == 0) \{\par
51         {\cf19 return} 1 / (1 + expf(-input)) * (1 - 1 / (1 + expf(-input)));\par
52     \}\par
53     {\cf19 if} (strcmp(af, {\cf22 "tanh"}) == 0) \{\par
54         {\cf19 return} 1 - powf(tanhf(input), 2);\par
55     \}\par
56     {\cf19 if} (strcmp(af, {\cf22 "relu"}) == 0) \{\par
57         {\cf19 if} (input < 0) \{\par
58             {\cf19 return} 0;\par
59         \}\par
60         {\cf19 return} 1;\par
61     \}\par
62     printf({\cf22 "Warning: Unknown activation function. Training results might not be optimal!\\n"});\par
63     printf({\cf22 "Defaulting to ReLu derivative\\n"});\par
64     {\cf19 if} (input < 0) \{\par
65         {\cf19 return} 0;\par
66     \}\par
67     {\cf19 return} 1;\par
68 \}\par
}
}
{\xe \v CNeural_clear_nodeResults\:CNeural.h}
{\xe \v CNeural.h\:CNeural_clear_nodeResults}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
void CNeural_clear_nodeResults ({\b NeuralNetwork} * nn, int layerNum)}}
\par
{\bkmkstart AAAAAAAAAO}
{\bkmkend AAAAAAAAAO}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Clears nodeResults array.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i nn} \cell }{neural network type \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i layerNum} \cell }{layer number \cell }
{\row }
}
}{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 80                                                                 \{\par
81     {\cf19 for} ({\cf18 int} i = 0; i < nn->layers[layerNum].nNodes; i++) \{\par
82         nn->layers[layerNum].nodesResults[i] = 0;\par
83     \}\par
84 \}\par
}
}
{\xe \v CNeural_derivatives\:CNeural.h}
{\xe \v CNeural.h\:CNeural_derivatives}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
void CNeural_derivatives ({\b NeuralNetwork} * nn, float inputs[], float labels[], string lossFunction)}}
\par
{\bkmkstart AAAAAAAAAP}
{\bkmkend AAAAAAAAAP}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Calculates the partial derivatives which combine to a gradient of all neural network parameters using backpropagation.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i nn} \cell }{neural network type \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i inputs} \cell }{array of inputs (features) \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i labels} \cell }{array of labels \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i lossFunction} \cell }{a string corresponding to a loss function \cell }
{\row }
}
}{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 22                                                                                                  \{\par
23     {\cf19 for} ({\cf18 int} layerNum = nn->nLayers - 1; layerNum >= 0; layerNum--) \{\par
24         {\cf19 for} ({\cf18 int} nodeNum = 0; nodeNum < nn->layers[layerNum].nNodes; nodeNum++) \{\par
25             {\cf19 if} (layerNum == 0) \{   {\cf20 // first layer (last layer in backprop)}\par
26                 {\cf19 for} ({\cf18 int} weightNum = 0; weightNum < nn->inShape; weightNum++) \{\par
27 \par
28                 \}\par
29             \} {\cf19 else} {\cf19 if} (layerNum == nn->nLayers - 1) \{ {\cf20 // last layers}\par
30                 {\cf19 for} ({\cf18 int} weightNum = 0; weightNum < nn->layers[layerNum - 1].nNodes; weightNum++) \{\par
31                     nn->layers[layerNum].nodes[nodeNum].weightDerivatives[weightNum] = nn->layers[layerNum-1].nodesResults[weightNum] * CNeural_af_derivative(nn->layers[layerNum].weightedSum[nodeNum], nn->layers[layerNum].nodes[nodeNum].AF) * CNeural_loss_derivative(nn->layers[layerNum].nodesResults[nodeNum], labels[nodeNum], lossFunction);\par
32                 \}\par
33                 {\cf20 // bias}\par
34             \} {\cf19 else} \{ {\cf20 // middle layers}\par
35 \par
36             \}\par
37         \}\par
38     \}\par
39 \}\par
}
}
{\xe \v CNeural_free\:CNeural.h}
{\xe \v CNeural.h\:CNeural_free}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
void CNeural_free ({\b NeuralNetwork} * nn)}}
\par
{\bkmkstart AAAAAAAAAQ}
{\bkmkend AAAAAAAAAQ}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Frees all allocated memory of a neural network.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i nn} \cell }{neural network type \cell }
{\row }
}
}{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 275                                      \{\par
276     {\cf20 // free(nn->)}\par
277     free(nn);\par
278 \}\par
}
}
{\xe \v CNeural_init\:CNeural.h}
{\xe \v CNeural.h\:CNeural_init}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
int CNeural_init ({\b NeuralNetwork} * nn, int inputShape, int outputShape, int numLayers, int layerNumNodes[], string layersAF[], string initMethod)}}
\par
{\bkmkstart AAAAAAAAAR}
{\bkmkend AAAAAAAAAR}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Initializes a neural network.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i nn} \cell }{neural network type \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i inputShape} \cell }{input number of nodes \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i outputShape} \cell }{output number of nodes \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i numLayers} \cell }{number of layers \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i layerNumNodes} \cell }{array with each layer's number of nodes \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i layersAF} \cell }{layer activation function \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i initMethod} \cell }{initialization method \cell }
{\row }
}
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Returns\par}\pard\plain \s82\li720\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
returns 0 for success \par
}}}{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 40                                                                                                                                                \{\par
41     nn->inShape = inputShape;\par
42     nn->outShape = outputShape;\par
43     nn->nLayers = numLayers;\par
44 \par
45     nn->layers = malloc({\cf17 sizeof}(Layer) * ({\cf18 unsigned} {\cf18 int}) nn->nLayers); {\cf20 // not freed}\par
46     {\cf19 if} (nn->layers == NULL) \{\par
47         printf({\cf22 "Error: Failed to allocate memory!"});\par
48         {\cf19 return} 1;\par
49     \}\par
50 \par
51     {\cf19 for} ({\cf18 int} i = 0; i < nn->nLayers; i++) \{ {\cf20 // initialize each LAYER with nodes and activation functions}\par
52         nn->layers[i].nNodes = layerNumNodes[i];\par
53         nn->layers[i].layerAF = layersAF[i];\par
54 \par
55 \par
56         nn->layers[i].nodes = malloc({\cf17 sizeof}(Node) * ({\cf18 unsigned} {\cf18 int}) nn->layers[i].nNodes); {\cf20 // not freed}\par
57         nn->layers[i].weightedSum = malloc({\cf17 sizeof}({\cf18 float}) * ({\cf18 unsigned} {\cf18 int}) nn->layers[i].nNodes); {\cf20 // not freed}\par
58         nn->layers[i].nodesResults = malloc({\cf17 sizeof}({\cf18 float}) * ({\cf18 unsigned} {\cf18 int}) nn->layers[i].nNodes); {\cf20 // not freed}\par
59         CNeural_clear_nodeResults(nn, i); {\cf20 // init with 0 to clear garbage values}\par
60 \par
61         {\cf19 if} (nn->layers[i].nodes == NULL || nn->layers[i].weightedSum == NULL || nn->layers[i].nodesResults == NULL) \{\par
62             printf({\cf22 "Error: Failed to allocate memory!"});\par
63             {\cf19 return} 1;\par
64         \}\par
65 \par
66         {\cf19 if} (CNeural_wb_init(nn, i, initMethod) != 0) \{\par
67             {\cf19 return} 1;\par
68         \}\par
69     \}\par
70 \par
71     {\cf19 return} 0;\par
72 \}\par
}
}
{\xe \v CNeural_loss\:CNeural.h}
{\xe \v CNeural.h\:CNeural_loss}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
float CNeural_loss (float predicted[], float actual[], int outputShape, string lfn)}}
\par
{\bkmkstart AAAAAAAAAS}
{\bkmkend AAAAAAAAAS}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Loss function. Helper function to CNeural_train.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i predicted} \cell }{array of predicted values (nodeResult values of the last layer) for 1 training example \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i actual} \cell }{array of label values to compare to for 1 training example \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i outputShape} \cell }{number of output nodes \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i lfn} \cell }{a string corresponding to a loss function, values: "mse", "mae", default: "mse" \cell }
{\row }
}
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Returns\par}\pard\plain \s82\li720\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
loss value \par
}}}{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 245                                                                                    \{\par
246     {\cf19 if} (strcmp(lfn, {\cf22 "mse"}) == 0) \{ {\cf20 // Mean Squared Error}\par
247         {\cf18 float} sum = 0;\par
248         {\cf19 for} ({\cf18 int} i = 0; i < outputShape; i++) \{\par
249             sum += powf(predicted[i] - actual[i], 2);\par
250         \}\par
251         {\cf19 return} sum;\par
252     \}\par
253     {\cf19 if} (strcmp(lfn, {\cf22 "mae"}) == 0) \{ {\cf20 // Mean Average Error}\par
254         {\cf18 float} sum = 0;\par
255         {\cf19 for} ({\cf18 int} i = 0; i < outputShape; i++) \{\par
256             sum += fabsf(predicted[i] - actual[i]);\par
257         \}\par
258         {\cf19 return} sum;\par
259     \}\par
260 \par
261     printf({\cf22 "Warning: Unknown loss function. Training results might not be optimal!\\n"});\par
262     printf({\cf22 "Defaulting to MSE\\n"});\par
263     {\cf18 float} sum = 0;\par
264     {\cf19 for} ({\cf18 int} i = 0; i < outputShape; i++) \{\par
265         sum += powf(predicted[i] - actual[i], 2);\par
266     \}\par
267     {\cf19 return} sum;\par
268 \}\par
}
}
{\xe \v CNeural_loss_derivative\:CNeural.h}
{\xe \v CNeural.h\:CNeural_loss_derivative}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
float CNeural_loss_derivative (float predicted, float actual, string lfn)}}
\par
{\bkmkstart AAAAAAAAAT}
{\bkmkend AAAAAAAAAT}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Calculates the partial derivative of the loss function with respect to nodeResults. Helper function to CNeural_derivatives.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i predicted} \cell }{array of predicted values (nodeResult values of the last layer) for 1 training example \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i actual} \cell }{array of label values to compare to for 1 training example \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i lfn} \cell }{a string corresponding to a loss function, values: "mse", "mae", default: "mse" \cell }
{\row }
}
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Returns\par}\pard\plain \s82\li720\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
rate of change of the loss function with respect to nodeResults \par
}}}{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 78                                                                          \{\par
79     {\cf19 if} (strcmp(lfn, {\cf22 "mse"}) == 0) \{\par
80         {\cf19 return} 2 * (predicted - actual);\par
81     \}\par
82     {\cf19 if} (strcmp(lfn, {\cf22 "mae"}) == 0) \{\par
83         {\cf20 // (might not be differentiable)}\par
84     \}\par
85 \par
86     printf({\cf22 "Warning: Unknown loss function. Training results might not be optimal!\\n"});\par
87     printf({\cf22 "Defaulting to MSE derivative\\n"});\par
88     {\cf19 return} 2 * (predicted - actual);\par
89 \}\par
}
}
{\xe \v CNeural_train\:CNeural.h}
{\xe \v CNeural.h\:CNeural_train}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
void CNeural_train ({\b NeuralNetwork} * nn, int numLabels, float inputs[numLabels][nn->inShape], float labels[numLabels][nn->outShape], string lossFunction, string optimizer, float learningRate, int epochs)}}
\par
{\bkmkstart AAAAAAAAAU}
{\bkmkend AAAAAAAAAU}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Trains a neural network using the specified parameters.\par
Weighted sums get forward propagated (forward pass) by calculating linear combinations applying an activation function for each node in each layer. After all the training examples go through 1 epoch, the loss and gradient are calculated based on the optimizer. Neural network parameters are adjusted with the learning rate accordingly.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i nn} \cell }{neural network type \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i numLabels} \cell }{number of labels (training examples) \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i inputs} \cell }{array of inputs (features) \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i labels} \cell }{array of labels \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i lossFunction} \cell }{a string corresponding to a loss function \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i optimizer} \cell }{a string corresponding to an optimizer \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i learningRate} \cell }{learning rate to be applied in gradient descent \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i epochs} \cell }{number of epochs (forward passes through the whole dataset) \cell }
{\row }
}
}{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 148                                                                                                                                                                                                          \{\par
149     nn->nLabels = numLabels;\par
150     nn->lf = lossFunction;\par
151     nn->opt = optimizer;\par
152     nn->lr = learningRate;\par
153     nn->epochs = epochs;\par
154 \par
155     {\cf20 // TODO loss and expand activation functions}\par
156     {\cf19 for} ({\cf18 int} epoch = 1; epoch <= nn->epochs; epoch++) \{\par
157         printf({\cf22 "Epoch %d/%d\\n"}, epoch, nn->epochs);\par
158         {\cf19 for} ({\cf18 int} label = 0; label < numLabels; label++) \{\par
159             {\cf20 // printf("Label: %d\\n", label + 1);}\par
160 \par
161             {\cf19 for} ({\cf18 int} layerNum = 0; layerNum < nn->nLayers; layerNum++) \{\par
162                 {\cf20 // printf("Layer %d\\n", layerNum + 1);}\par
163 \par
164                 {\cf19 for} ({\cf18 int} nodeNum = 0; nodeNum < nn->layers[layerNum].nNodes; nodeNum++) \{\par
165                     {\cf20 // printf("\\tNode %d\\n", nodeNum + 1);}\par
166                     {\cf19 if} (layerNum == 0) \{ {\cf20 // 1st layer # of weights should = # of inputs}\par
167                         {\cf19 for} ({\cf18 int} weightNum = 0; weightNum < nn->inShape; weightNum++) \{\par
168                             {\cf20 // printf("\\t\\tWeight %d: %f ", weightNum + 1, nn->layers[0].nodes[nodeNum].weights[weightNum]);}\par
169                             nn->layers[layerNum].nodesResults[nodeNum] +=\par
170                                 nn->layers[layerNum].nodes[nodeNum].weights[weightNum] * inputs[label][weightNum]; {\cf20 // adds for each linear combination (weighted sum)}\par
171 \par
172                             {\cf20 // printf("Noderes value: %f\\n", nn->layers[0].nodesResults[nodeNum]);}\par
173                         \}\par
174                     \} {\cf19 else} \{  {\cf20 // # of weights should = previous layer # of nodes}\par
175                         {\cf19 for} ({\cf18 int} weightNum = 0; weightNum < nn->layers[layerNum - 1].nNodes; weightNum++) \{\par
176                             {\cf20 // printf("\\t\\tWeight %d: %f \\t", weightNum + 1, nn->layers[layerNum].nodes[nodeNum].weights[weightNum]);}\par
177                             nn->layers[layerNum].nodesResults[nodeNum] +=\par
178                                 nn->layers[layerNum].nodes[nodeNum].weights[weightNum] * nn->layers[layerNum - 1].nodesResults[weightNum]; {\cf20 // adds for each linear combination (weighted sum)}\par
179                             {\cf20 // printf("Noderes value: %f\\n", nn->layers[layerNum].nodesResults[nodeNum]);}\par
180                         \}\par
181                     \}\par
182                     nn->layers[layerNum].nodesResults[nodeNum] += nn->layers[layerNum].nodes[nodeNum].bias;\par
183                     {\cf20 // printf("\\n");}\par
184                     {\cf20 // printf("\\t\\tAfter bias: %f\\n", nn->layers[layerNum].nodesResults[nodeNum]);}\par
185 \par
186                     {\cf20 // printf("\\t\\tAfter activation: %f\\n", CNeural_activation(nn->layers[layerNum].nodesResults[nodeNum], nn->layers[layerNum].nodes[nodeNum].AF));}\par
187                     nn->layers[layerNum].weightedSum[nodeNum] = nn->layers[layerNum].nodesResults[nodeNum];\par
188                     nn->layers[layerNum].nodesResults[nodeNum] =\par
189                         CNeural_activation(nn->layers[layerNum].nodesResults[nodeNum], nn->layers[layerNum].nodes[nodeNum].AF);\par
190                     {\cf20 // printf("\\n");}\par
191                 \}\par
192 \par
193                 {\cf20 // printf("\\n");}\par
194             \}\par
195 \par
196             nn->loss += CNeural_loss(nn->layers[nn->nLayers - 1].nodesResults, labels[label], nn->outShape, nn->lf);\par
197 \par
198             {\cf20 // CNeural_derivatives()}\par
199 \par
200             {\cf19 for} ({\cf18 int} layerNum = 0; layerNum < nn->nLayers; layerNum++) \{ {\cf20 // clear after each label}\par
201                 CNeural_clear_nodeResults(nn, layerNum);\par
202             \}\par
203         \}\par
204         nn->loss = nn->loss / (float) nn->nLabels;\par
205         printf({\cf22 "Loss: %f\\n"}, nn->loss);\par
206         printf({\cf22 "\\n"});\par
207 \par
208     \}\par
209 \par
210 \}\par
}
}
{\xe \v CNeural_wb_init\:CNeural.h}
{\xe \v CNeural.h\:CNeural_wb_init}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
int CNeural_wb_init ({\b NeuralNetwork} * nn, int layerNum, string option)}}
\par
{\bkmkstart AAAAAAAAAV}
{\bkmkend AAAAAAAAAV}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Initializes the weights and biases. Helper function to CNeural_init.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i nn} \cell }{neural network type \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i layerNum} \cell }{layer number \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i option} \cell }{a string corresponding to an initialization method, values: "zero", "random" \cell }
{\row }
}
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Returns\par}\pard\plain \s82\li720\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
returns 0 for sucess \par
}}}{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 94                                                                     \{\par
95     {\cf20 //TODO (optional) calculate mean, variance, standard deviation for measuring appropriateness}\par
96     srand(({\cf18 unsigned} {\cf18 int}) time(NULL)); {\cf20 // init random generator}\par
97 \par
98     {\cf19 if} (strcmp(option, {\cf22 "zero"}) == 0) \{\par
99         {\cf20 // probably not a good init option}\par
100     \} {\cf19 else} {\cf19 if} (strcmp(option, {\cf22 "random"}) == 0) \{\par
101         {\cf19 for} ({\cf18 int} i = 0; i < nn->layers[layerNum].nNodes; i++) \{ {\cf20 // for each NODE in layer init weights}\par
102             {\cf19 if} (layerNum == 0) \{ {\cf20 // first layer # of weights should = # of inputs}\par
103                 nn->layers[layerNum].nodes[i].weights = malloc({\cf17 sizeof}({\cf18 float}) * ({\cf18 unsigned} {\cf18 int}) nn->inShape); {\cf20 // not freed}\par
104                 nn->layers[layerNum].nodes[i].weightDerivatives = malloc({\cf17 sizeof}({\cf18 float}) * ({\cf18 unsigned} {\cf18 int}) nn->inShape); {\cf20 // not freed}\par
105                 {\cf19 if} (nn->layers[layerNum].nodes[i].weights == NULL || nn->layers[layerNum].nodes[i].weightDerivatives == NULL) \{ printf({\cf22 "Error: Failed to allocate memory!"}); {\cf19 return} 1; \}\par
106                 {\cf19 for} ({\cf18 int} j = 0; j < nn->inShape; j++) \{ {\cf20 // for each WEIGHT in node}\par
107                     nn->layers[layerNum].nodes[i].weights[j] = (float) (rand() / (({\cf18 double}) RAND_MAX + 1.0));\par
108                     nn->layers[layerNum].nodes[i].weightDerivatives[j] = 0;\par
109                 \}\par
110             \} {\cf19 else} \{  {\cf20 // # of weights should = previous layer # of nodes}\par
111                 nn->layers[layerNum].nodes[i].weights = malloc({\cf17 sizeof}({\cf18 float}) * ({\cf18 unsigned} {\cf18 int}) nn->layers[layerNum - 1].nNodes); {\cf20 // not freed}\par
112                 nn->layers[layerNum].nodes[i].weightDerivatives = malloc({\cf17 sizeof}({\cf18 float}) * ({\cf18 unsigned} {\cf18 int}) nn->inShape); {\cf20 // not freed}\par
113                 {\cf19 if} (nn->layers[layerNum].nodes[i].weights == NULL || nn->layers[layerNum].nodes[i].weightDerivatives == NULL) \{ printf({\cf22 "Error: Failed to allocate memory!"}); {\cf19 return} 1; \}\par
114                 {\cf19 for} ({\cf18 int} j = 0; j < nn->layers[layerNum - 1].nNodes; j++) \{ {\cf20 // for each WEIGHT in node}\par
115                     nn->layers[layerNum].nodes[i].weights[j] = (float) (rand() / (({\cf18 double}) RAND_MAX + 1.0));\par
116                     nn->layers[layerNum].nodes[i].weightDerivatives[j] = 0;\par
117                 \}\par
118             \}\par
119             nn->layers[layerNum].nodes[i].bias = 0; {\cf20 // bias can be 0}\par
120             nn->layers[layerNum].nodes[i].biasDerivative = 0;\par
121             nn->layers[layerNum].nodes[i].AF = nn->layers[layerNum].layerAF; {\cf20 // applies to the whole layer}\par
122         \}\par
123     \} {\cf19 else} \{\par
124         printf({\cf22 "Error: Unknown initialization method."});\par
125         {\cf19 return} 1;\par
126     \}\par
127 \par
128     {\cf19 return} 0;\par
129 \}\par
}
}
\par \pard\plain 

\pard\plain \sect\sbkpage
\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
CNeural.h\par \pard\plain 
{\tc\tcl2 \v CNeural.h}
{\xe \v CNeural.h}
{\bkmkstart AAAAAAAAAA}
{\bkmkend AAAAAAAAAA}
Go to the documentation of this file.\par
{
\par
\pard\plain \s40\li0\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 1 \par
9 {\cf21 #ifndef CNEURAL_H}\par
10 {\cf21 #define CNEURAL_H}\par
11 {\cf17 typedef} {\cf18 char}* string;\par
12 \par
18 {\cf17 typedef} {\cf17 struct }\{\par
19     {\cf18 float} *weights; \par
20     {\cf18 float} bias; \par
21     {\cf18 float} *weightDerivatives; \par
22     {\cf18 float} biasDerivative; \par
24     {\cf18 string} AF; \par
25 \} Node;\par
26 \par
32 {\cf17 typedef} {\cf17 struct }\{\par
33     {\cf18 int} nNodes; \par
34     Node *nodes; \par
36     {\cf18 string} layerAF; \par
37     {\cf18 float} *weightedSum; \par
38     {\cf18 float} *nodesResults; \par
39 \} Layer;\par
40 \par
44 {\cf17 typedef} {\cf17 struct }\{\par
45     {\cf18 int} inShape; \par
46     {\cf18 int} nLayers; \par
47     {\cf18 int} outShape; \par
48     {\cf18 int} nLabels; \par
49     {\cf18 string} lf; \par
50     {\cf18 float} loss; \par
51     {\cf18 string} opt; \par
52     {\cf18 float} lr; \par
53     {\cf18 int} epochs; \par
55     {\cf18 float} *labels; \par
56     Layer *layers; \par
57 \} NeuralNetwork;\par
58 \par
59 \par
60 {\cf18 int} CNeural_init(NeuralNetwork *nn, {\cf18 int} inputShape, {\cf18 int} outputShape, {\cf18 int} numLayers, {\cf18 int} layerNumNodes[], {\cf18 string} layersAF[], {\cf18 string} initMethod);\par
61 {\cf18 void} CNeural_clear_nodeResults(NeuralNetwork *nn, {\cf18 int} layerNum);\par
62 {\cf18 int} CNeural_wb_init(NeuralNetwork *nn, {\cf18 int} layerNum, {\cf18 string} option);\par
63 {\cf18 void} CNeural_train(NeuralNetwork *nn, {\cf18 int} numLabels, {\cf18 float} inputs[numLabels][nn->inShape], {\cf18 float} labels[numLabels][nn->outShape], {\cf18 string} lossFunction, {\cf18 string} optimizer, {\cf18 float} learningRate, {\cf18 int} epochs);\par
64 {\cf18 float} CNeural_activation({\cf18 float} input, {\cf18 string} af);\par
65 {\cf18 float} CNeural_loss({\cf18 float} predicted[], {\cf18 float} actual[], {\cf18 int} outputShape, {\cf18 string} lfn);\par
66 {\cf18 void} CNeural_free(NeuralNetwork *nn);\par
67 \par
68 {\cf18 void} CNeural_derivatives(NeuralNetwork *nn, {\cf18 float} inputs[], {\cf18 float} labels[], {\cf18 string} lossFunction);\par
69 {\cf18 float} CNeural_af_derivative({\cf18 float} input, {\cf18 string} af);\par
70 {\cf18 float} CNeural_loss_derivative({\cf18 float} predicted, {\cf18 float} actual, {\cf18 string} lfn);\par
71 {\cf21 #endif }{\cf20 //CNEURAL_H}\par
}
\par \pard\plain 

\pard\plain \sect\sbkpage
\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
CNeural_backpropagation.c File Reference\par \pard\plain 
{\tc\tcl2 \v CNeural_backpropagation.c}
{\xe \v CNeural_backpropagation.c}
{\bkmkstart AAAAAAAAAW}
{\bkmkend AAAAAAAAAW}
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Source file for CNeural backpropagation, containing function definitions. }}\par
{
\pard\plain \s18\widctlpar\fs22\cgrid {\f2 #include "CNeural.h"}\par
{\f2 #include <string.h>}\par
{\f2 #include <math.h>}\par
{\f2 #include <stdio.h>}\par
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Functions\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
void {\b CNeural_derivatives} ({\b NeuralNetwork} *nn, float inputs[], float labels[], string lossFunction)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
float {\b CNeural_af_derivative} (float input, string af)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
float {\b CNeural_loss_derivative} (float predicted, float actual, string lfn)\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Detailed Description\par
\pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Source file for CNeural backpropagation, containing function definitions. \par
}{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Author\par}\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
Dai Duong Le \par
}}{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Version\par}\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
: 0.0.1 \par
}}}}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Function Documentation\par
\pard\plain 
{\xe \v CNeural_af_derivative\:CNeural_backpropagation.c}
{\xe \v CNeural_backpropagation.c\:CNeural_af_derivative}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
float CNeural_af_derivative (float input, string af)}}
\par
{\bkmkstart AAAAAAAAAX}
{\bkmkend AAAAAAAAAX}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Calculates the partial derivative of the activation function with respect to a weighted sum. Helper function to CNeural_derivatives.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i input} \cell }{value of weighted sum \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i af} \cell }{a string corresponding to an activation function, values: "none", "sigmoid", "tanh", "relu", default: "relu" \cell }
{\row }
}
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Returns\par}\pard\plain \s82\li720\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
rate of change of the activation function with respect to a weighted sum \par
}}}{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 48                                                     \{\par
49     {\cf19 if} (strcmp(af, {\cf22 "none"}) == 0) {\cf19 return} 1;\par
50     {\cf19 if} (strcmp(af, {\cf22 "sigmoid"}) == 0) \{\par
51         {\cf19 return} 1 / (1 + expf(-input)) * (1 - 1 / (1 + expf(-input)));\par
52     \}\par
53     {\cf19 if} (strcmp(af, {\cf22 "tanh"}) == 0) \{\par
54         {\cf19 return} 1 - powf(tanhf(input), 2);\par
55     \}\par
56     {\cf19 if} (strcmp(af, {\cf22 "relu"}) == 0) \{\par
57         {\cf19 if} (input < 0) \{\par
58             {\cf19 return} 0;\par
59         \}\par
60         {\cf19 return} 1;\par
61     \}\par
62     printf({\cf22 "Warning: Unknown activation function. Training results might not be optimal!\\n"});\par
63     printf({\cf22 "Defaulting to ReLu derivative\\n"});\par
64     {\cf19 if} (input < 0) \{\par
65         {\cf19 return} 0;\par
66     \}\par
67     {\cf19 return} 1;\par
68 \}\par
}
}
{\xe \v CNeural_derivatives\:CNeural_backpropagation.c}
{\xe \v CNeural_backpropagation.c\:CNeural_derivatives}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
void CNeural_derivatives ({\b NeuralNetwork} * nn, float inputs[], float labels[], string lossFunction)}}
\par
{\bkmkstart AAAAAAAAAY}
{\bkmkend AAAAAAAAAY}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Calculates the partial derivatives which combine to a gradient of all neural network parameters using backpropagation.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i nn} \cell }{neural network type \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i inputs} \cell }{array of inputs (features) \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i labels} \cell }{array of labels \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i lossFunction} \cell }{a string corresponding to a loss function \cell }
{\row }
}
}{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 22                                                                                                  \{\par
23     {\cf19 for} ({\cf18 int} layerNum = nn->nLayers - 1; layerNum >= 0; layerNum--) \{\par
24         {\cf19 for} ({\cf18 int} nodeNum = 0; nodeNum < nn->layers[layerNum].nNodes; nodeNum++) \{\par
25             {\cf19 if} (layerNum == 0) \{   {\cf20 // first layer (last layer in backprop)}\par
26                 {\cf19 for} ({\cf18 int} weightNum = 0; weightNum < nn->inShape; weightNum++) \{\par
27 \par
28                 \}\par
29             \} {\cf19 else} {\cf19 if} (layerNum == nn->nLayers - 1) \{ {\cf20 // last layers}\par
30                 {\cf19 for} ({\cf18 int} weightNum = 0; weightNum < nn->layers[layerNum - 1].nNodes; weightNum++) \{\par
31                     nn->layers[layerNum].nodes[nodeNum].weightDerivatives[weightNum] = nn->layers[layerNum-1].nodesResults[weightNum] * CNeural_af_derivative(nn->layers[layerNum].weightedSum[nodeNum], nn->layers[layerNum].nodes[nodeNum].AF) * CNeural_loss_derivative(nn->layers[layerNum].nodesResults[nodeNum], labels[nodeNum], lossFunction);\par
32                 \}\par
33                 {\cf20 // bias}\par
34             \} {\cf19 else} \{ {\cf20 // middle layers}\par
35 \par
36             \}\par
37         \}\par
38     \}\par
39 \}\par
}
}
{\xe \v CNeural_loss_derivative\:CNeural_backpropagation.c}
{\xe \v CNeural_backpropagation.c\:CNeural_loss_derivative}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
float CNeural_loss_derivative (float predicted, float actual, string lfn)}}
\par
{\bkmkstart AAAAAAAAAZ}
{\bkmkend AAAAAAAAAZ}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Calculates the partial derivative of the loss function with respect to nodeResults. Helper function to CNeural_derivatives.\par
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Parameters\par}
\pard\plain \s81\li360\widctlpar\ql\adjustright \fs20\cgrid \trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i predicted} \cell }{array of predicted values (nodeResult values of the last layer) for 1 training example \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i actual} \cell }{array of label values to compare to for 1 training example \cell }
{\row }
\trowd \trgaph108\trleft426\tblind426\trbrdrt\brdrs\brdrw10\brdrcf15 \trbrdrl\brdrs\brdrw10\brdrcf15 \trbrdrb\brdrs\brdrw10\brdrcf15 \trbrdrr\brdrs\brdrw10\brdrcf15 \trbrdrh\brdrs\brdrw10\brdrcf15 \trbrdrv\brdrs\brdrw10\brdrcf15 
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx2187
\clvertalt\clbrdrt\brdrs\brdrw10\brdrcf15 \clbrdrl\brdrs\brdrw10\brdrcf15 \clbrdrb\brdrs\brdrw10\brdrcf15 \clbrdrr \brdrs\brdrw10\brdrcf15 \cltxlrtb \cellx8748
\pard \widctlpar\intbl\adjustright
{{\i lfn} \cell }{a string corresponding to a loss function, values: "mse", "mae", default: "mse" \cell }
{\row }
}
{{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs16\cgrid 
Returns\par}\pard\plain \s82\li720\widctlpar\ql\adjustright \fs20\cgrid {\s17 \sa60 \sb30
rate of change of the loss function with respect to nodeResults \par
}}}{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 78                                                                          \{\par
79     {\cf19 if} (strcmp(lfn, {\cf22 "mse"}) == 0) \{\par
80         {\cf19 return} 2 * (predicted - actual);\par
81     \}\par
82     {\cf19 if} (strcmp(lfn, {\cf22 "mae"}) == 0) \{\par
83         {\cf20 // (might not be differentiable)}\par
84     \}\par
85 \par
86     printf({\cf22 "Warning: Unknown loss function. Training results might not be optimal!\\n"});\par
87     printf({\cf22 "Defaulting to MSE derivative\\n"});\par
88     {\cf19 return} 2 * (predicted - actual);\par
89 \}\par
}
}

\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid Index\par 
\pard\plain 
{\tc \v Index}
{\field\fldedit {\*\fldinst INDEX \\c2 \\*MERGEFORMAT}{\fldrslt INDEX}}
}
